{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from utils import *\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, Y, layer_dims, num_iterations=2000, learning_rate=0.01, printCost=False):\n",
    "    \n",
    "    #Initialize Parameters\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    costs = []\n",
    "    \n",
    "    #Start Learning\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        #Forward Propagate\n",
    "        AL, cache = forwardPropagation(X, parameters)\n",
    "        \n",
    "        #Find Cost\n",
    "        cost = computeCost(AL, Y)\n",
    "        if printCost and i%100==0:\n",
    "            print(\"Cost at iteration \" + str(i) + \" is \" + str(cost))\n",
    "            costs.append(cost)\n",
    "        \n",
    "        #Back Propagate\n",
    "        grads = backPropagation(AL, Y, cache)\n",
    "        \n",
    "        #Update Parameters\n",
    "        parameters = updateParameters(parameters, grads, learning_rate)\n",
    "    \n",
    "    #plot cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('number of iterations')\n",
    "    plt.title('Learning Rate: ' + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "\n",
    "def predict(X, Y, final_parameters):\n",
    "    probabs, cache = forwardPropagation(X, final_parameters)\n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1, m), dtype=float)\n",
    "    for i in range(probabs.shape[1]):\n",
    "        if probabs[0, i] >= 0.5:\n",
    "            p[0, i] = 1\n",
    "        else:\n",
    "            p[0, i] = 0\n",
    "    print(\"Accuracy: \" + str(np.sum((p == Y)/m)))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0 is 0.6931470866606373\n",
      "Cost at iteration 100 is 0.6740962013004754\n",
      "Cost at iteration 200 is 0.66252057190309\n",
      "Cost at iteration 300 is 0.6554527843799112\n",
      "Cost at iteration 400 is 0.6511123324740153\n",
      "Cost at iteration 500 is 0.6484315588575524\n",
      "Cost at iteration 600 is 0.6467672860081753\n",
      "Cost at iteration 700 is 0.6457294515146055\n",
      "Cost at iteration 800 is 0.6450798201645187\n",
      "Cost at iteration 900 is 0.6446719122564109\n",
      "Cost at iteration 1000 is 0.6444151269822956\n",
      "Cost at iteration 1100 is 0.644253138429838\n",
      "Cost at iteration 1200 is 0.6441507778582399\n",
      "Cost at iteration 1300 is 0.6440860079145393\n",
      "Cost at iteration 1400 is 0.6440449788893884\n",
      "Cost at iteration 1500 is 0.6440189658014857\n",
      "Cost at iteration 1600 is 0.6440024613978641\n",
      "Cost at iteration 1700 is 0.6439919839866481\n",
      "Cost at iteration 1800 is 0.6439853296420367\n",
      "Cost at iteration 1900 is 0.6439811018455981\n",
      "Cost at iteration 2000 is 0.6439784149593951\n",
      "Cost at iteration 2100 is 0.6439767069673583\n",
      "Cost at iteration 2200 is 0.6439756210322087\n",
      "Cost at iteration 2300 is 0.643974930493521\n",
      "Cost at iteration 2400 is 0.6439744913297124\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAEWCAYAAAA5Am/SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcXHWd7vHPU70l3dm6O50ISbo7\nQCJLwJA0QQUUXAEXQByE0RkZ58o4M1wHcbzi3FEZ0HEZlxkd7oyguIwibghBUeIoqAMG0gECJCEY\nQjYSks6+dtLL9/5xTkOl6U5XJ1VdvTzv16tefeqcX536nip48jtL/Y4iAjMzO3qZYhdgZjZcOFDN\nzPLEgWpmlicOVDOzPHGgmpnliQPVzCxPHKg2KEn6haT3FrsOs/5woNohJK2W9IZi1xERF0TEt/O9\nXknnSuqUtEfSbkkrJP1FP15/vaTv5rmmD0l6XtJOSbdKqjhM29dLekrSPkn3SWrIWnaZpAfTZffn\ns0bLjQPVBpyk0iKXsCEixgDjgA8Bt0h6eTEKkfRm4Drg9UAjcBzwT720nQjcAXwcqAGagR9kNdkG\n/Cvw2cJVbIfjQLWcSXqrpMck7Uh7QqdlLbtO0jNpr2+ZpEuyll0p6QFJX5a0Dbg+nfc/kr4gabuk\nZyVdkPWa+yX9r6zXH67tdEm/S9/7vyXdlEsvMhL3kARR9rb8m6R1knZJWizpnHT++cA/AO9Ke7hL\n0vnjJX1D0kZJz0n6lKSSHD/W9wLfiIilEbEduBG4spe27wCWRsSPIqIVuB54haQT0+3574j4IbAh\nx/e2PHOgWk4kzQFuBf4KqAW+BszP2j19BjgHGE/Sw/qupGOyVnEmsAqYBHw6a94KYCLweeAbktRL\nCYdrexvwcFrX9cCf5bhNGUlvT9e5MmvRImA2SS/wNuBHkkZFxC+BfwZ+EBFjIuIVaftvA+3ACcDp\nwJuArn8M6tN/gOp7KeMUYEnW8yXAZEm1fbWNiL0kn/spuWyvFZ4D1XL1fuBrEfFQRHSkxzcPAK8E\nSHtNGyKiMyJ+APwRmJf1+g0R8dWIaI+I/em8NRFxS0R0kITSMcDkXt6/x7ZpUJ0BfCIiDkbE/wDz\n+9iWYyXtAPYDPwWujYhHuxZGxHcjYmta6xeBCqDHQwKSJgMXANdExN6I2Ax8Gbg8XdfaiJgQEWt7\nqWUMsDPredf02BzadrXvqa0VgQPVctUAfDjtbe1IA2kacCyApD/POhywA5hF0vPrsq6HdT7fNRER\n+9LJMb28f29tjwW2Zc3r7b2ybYiICSTHUL8CvC57oaQPS1qeniTaQdLrntjDeiD5XMqAjVnb/jWS\nnngu9qR1dOma3p1D2672PbW1InCgWq7WAZ9Oe1tdj8qI+H56pvkW4GqgNg2rJ4Hs3fdCDWu2EaiR\nVJk1b1ouL4yIA8BHgVMlXQyQHi/9KHAZUJ1uy05e3Jbu27GOpKc+MetzGRcRue6GLwVekfX8FcCm\niNjaV1tJVcDx6XwbBByo1pMySaOyHqUkgfkBSWcqUSXpLZLGAlUkQdMCkF6GNGsgCo2INSRnu6+X\nVC7pVcDb+vH6g8AXgU+ks8aSHA9tAUolfYJDe4WbgEZJmfT1G4EFwBcljUuPyx4v6bU5lvAd4C8l\nnSypGvhH4Fu9tP0pMEvSpZJGpTU/HhFPAUgqSeeXApn0uyvLsQ7LAweq9eQekuOLXY/rI6KZ5Djq\nvwPbSU7iXAkQEctIQukPJIFzKvDAANb7buBVwFbgUySXEh3ox+tvBeolvQ24F/gF8DSwBmjl0EMI\nP0r/bpX0SDr950A5sIzks/kxyTHerpNSe3o7KZWe6Po8cF/6fmuAT3Ytl7RU0rvTti3ApSQn9baT\nnKi7PGt1f0byff0HyQnC/ST/ENoAkQeYtuFG0g+ApyLik302Nssj91BtyJN0RrqbnUmvFb0IuLPY\nddnIU+xfrJjlw8tIfkFUC6wH/jr7MiizgeJdfjOzPPEuv5lZngybXf6JEydGY2Njscsws2Fm8eLF\nWyKiLpe2wyZQGxsbaW5uLnYZZjbMSFqTa1vv8puZ5YkD1cwsTxyoZmZ54kA1M8sTB6qZWZ44UM3M\n8sSBamaWJyM2UO9d+jy3/G5Vscsws2FkxAbqb59u4ab7V/bd0MwsRyM2UBtqKtmxr42d+9uKXYqZ\nDRMjN1BrqwBYu3VfHy3NzHIzggM1uafb6q17i1yJmQ0XIzZQ62uSQF27zT1UM8uPERuoVRWl1I2t\nYI17qGaWJyM2UCE5MbXax1DNLE9GdKDW11b6pJSZ5c2IDtTG2iqe39VKa1tHsUsxs2FgRAdq15l+\nn5gys3woaKBKOl/SCkkrJV3XS5vLJC2TtFTSbVnzPyfpyfTxrkLU13Wmf413+80sDwp2TylJJcBN\nwBtJ7pW+SNL8iFiW1WYG8DHgrIjYLmlSOv8twBxgNlAB/FbSLyJiVz5rbEwv7veZfjPLh0L2UOcB\nKyNiVUQcBG4HLurW5v3ATRGxHSAiNqfzTwZ+GxHtEbEXWAKcn+8CJ1SWMXZUqXuoZpYXhQzUKcC6\nrOfr03nZZgIzJT0gaaGkrtBcAlwgqVLSROA8YFr3N5B0laRmSc0tLS39LlASDbWVrPExVDPLg0Le\nRlo9zIse3n8GcC4wFfi9pFkRsUDSGcCDQAvwB6D9JSuLuBm4GaCpqan7unPSUFvF0ud2HslLzcwO\nUcge6noO7VVOBTb00OauiGiLiGeBFSQBS0R8OiJmR8QbScL5j4UosqGmkvXb99Pe0VmI1ZvZCFLI\nQF0EzJA0XVI5cDkwv1ubO0l250l37WcCqySVSKpN558GnAYsKESRDbWVtHcGG3a0FmL1ZjaCFGyX\nPyLaJV0N3AuUALdGxFJJNwDNETE/XfYmScuADuAjEbFV0iiS3X+AXcB7IuIlu/z5UF+Tnunftpf6\n9LpUM7MjUchjqETEPcA93eZ9Ims6gGvTR3abVpIz/QXXOLFrGL99nDNjIN7RzIarEf1LKYDJY0dR\nXpphra9FNbOjNOIDNZMR9TWVvhbVzI7aiA9UgMbaSv+e38yOmgOV5MTUmq37SA7pmpkdGQcqyaVT\n+9s6aNl9oNilmNkQ5kDlxWH8/BNUMzsaDlRevKX06i0+029mR86BCkyZMJqMPNC0mR0dBypQXpph\nSvVoXzplZkfFgZpqqKnyQNNmdlQcqKl6j4tqZkfJgZpqrK1kx742du5rK3YpZjZEOVBT2aNOmZkd\nCQdq6oVrUX1iysyOkAM11RWovnTKzI6UAzVVWV5K3dgKX9xvZkfMgZqlocZn+s3syDlQszTUVrHW\nx1DN7Ag5ULM01Fby/K5WWts6il2KmQ1BDtQsPjFlZkfDgZqla9QpXzplZkfCgZqloabrWlSf6Tez\n/nOgZplQWcbYUaXuoZrZEXGgZpFEY22VL50ysyPiQO2mvrbSu/xmdkQcqN001FTy3Pb9tHd0FrsU\nMxtiHKjdNNZW0d4ZbNjRWuxSzGyIcaB2U//CHVC9229m/eNA7abr4v7VPtNvZv3kQO1m8thRVJRm\nWOsTU2bWTw7UbjIZUV9T6WtRzazfChqoks6XtELSSknX9dLmMknLJC2VdFvW/M+n85ZL+ookFbLW\nbA21DlQz67+CBaqkEuAm4ALgZOAKSSd3azMD+BhwVkScAlyTzn81cBZwGjALOAN4baFq7a6htoq1\n2/YREQP1lmY2DBSyhzoPWBkRqyLiIHA7cFG3Nu8HboqI7QARsTmdH8AooByoAMqATQWs9RANtZXs\nb+ugZfeBgXpLMxsGChmoU4B1Wc/Xp/OyzQRmSnpA0kJJ5wNExB+A+4CN6ePeiFje/Q0kXSWpWVJz\nS0tL3gqvr/GZfjPrv0IGak/HPLvvQ5cCM4BzgSuAr0uaIOkE4CRgKkkIv07Sa16ysoibI6IpIprq\n6uryVnjjC8P4+Uy/meWukIG6HpiW9XwqsKGHNndFRFtEPAusIAnYS4CFEbEnIvYAvwBeWcBaDzGl\nejQlGXmgaTPrl0IG6iJghqTpksqBy4H53drcCZwHIGkiySGAVcBa4LWSSiWVkZyQeskuf6GUlWQ4\ndsIo7/KbWb8ULFAjoh24GriXJAx/GBFLJd0g6e1ps3uBrZKWkRwz/UhEbAV+DDwDPAEsAZZExN2F\nqrUnjbVVvrjfzPqltJArj4h7gHu6zftE1nQA16aP7DYdwF8Vsra+1NdU8vMnNhazBDMbYvxLqV40\n1FayY18bO/e1FbsUMxsiHKi9eOGGfR51ysxy5EDtRdeoU/4JqpnlyoHai3rfAdXM+smB2ovK8lIm\nja1wD9XMcuZAPYyG2krfAdXMcuZAPYz6mirv8ptZzhyoh9FYW8mmXQdobesodilmNgQ4UA+j64Z9\n/k2/meXCgXoYXdeirt7i3X4z65sD9TAa3UM1s35woB7GhMpyxo0q9aVTZpYTB2ofGmqrfOmUmeXE\ngdqH5A6oPoZqZn1zoPahobaS57bvp72js9ilmNkg50DtQ0NNFe2dwYYdrcUuxcwGOQdqH7pGnVrt\n3X4z64MDtQ8NvgOqmeXIgdqHyeMqqKkqZ8n6ncUuxcwGOQdqHyQxp76aR9ZsL3YpZjbIOVBzMLeh\nmlVb9rJt78Fil2Jmg5gDNQdzG6oB3Es1s8NyoObgtKnjKc2IxWsdqGbWOwdqDkaVlXDKlPEsdg/V\nzA7DgZqjpoZqlqzbQZt/MWVmvXCg5mhuQzUH2jtZumFXsUsxs0HKgZqjrhNT3u03s944UHM0edwo\npkwY7TP9ZtYrB2o/zG2opnnNNiKi2KWY2SDkQO2HuQ3VbNp1gA07PfKUmb2UA7UffBzVzA6noIEq\n6XxJKyStlHRdL20uk7RM0lJJt6XzzpP0WNajVdLFhaw1Fye+bCyV5SU+jmpmPcopUCX9SS7zui0v\nAW4CLgBOBq6QdHK3NjOAjwFnRcQpwDUAEXFfRMyOiNnA64B9wIJcai2k0pIMs6dNoHnNtmKXYmaD\nUK491I/lOC/bPGBlRKyKiIPA7cBF3dq8H7gpIrYDRMTmHtbzTuAXETEo7pQ3t6Ga5Rt3s/dAe7FL\nMbNBpvRwCyVdAFwITJH0laxF44C+EmUKsC7r+XrgzG5tZqbv8wBQAlwfEb/s1uZy4Eu91HcVcBVA\nfX19H+Xkx5yGajo6gyXrd/Dq4ycOyHua2dDQVw91A9AMtAKLsx7zgTf38Vr1MK/79UalwAzgXOAK\n4OuSJrywAukY4FTg3p7eICJujoimiGiqq6vro5z8mDPNI0+ZWc8O20ONiCXAEkm3RUQbgKRqYFrX\nbvphrAemZT2fShLQ3dssTNf9rKQVJAG7KF1+GfDTrvceDMZXljFj0hif6Tezl8j1GOqvJI2TVAMs\nAb4pqcfd8CyLgBmSpksqJ9l1n9+tzZ3AeQCSJpIcAliVtfwK4Ps51jhg5jZU88jaHXR2+gJ/M3tR\nroE6PiJ2Ae8AvhkRc4E3HO4FEdEOXE2yu74c+GFELJV0g6S3p83uBbZKWgbcB3wkIrYCSGok6eH+\ntn+bVHhzGqrZub+NVVv2FLsUMxtEDrvLn90uPZ55GfB/c115RNwD3NNt3ieypgO4Nn10f+1qkhNb\ng05TeoF/8+rtnDBpbJGrMbPBItce6g0kvclnImKRpOOAPxaurMFt+sQqqivLfBzVzA6RUw81In4E\n/Cjr+Srg0kIVNdhJYm5DtW+JYmaHyPWXUlMl/VTSZkmbJP1E0tRCFzeYzWmoZlWL74RqZi/KdZf/\nmyRn6I8lOa55dzpvxJpbnxxHfdS9VDNL5RqodRHxzYhoTx/fAgbmSvpB6rSpE5I7ofo4qpmlcg3U\nLZLeI6kkfbwH2FrIwga70eUlnHLsOAeqmb0g10B9H8klU88DG0kGLPmLQhU1VMxpqGbJet8J1cwS\nuQbqjcB7I6IuIiaRBOz1BatqiGhqqKG1rZNlvhOqmZF7oJ6W/dv9iNgGnF6YkoaOOQ3JOC7e7Tcz\nyD1QM+mgKACkv+nP9VdWw9Yx40czZcJoX49qZkDuofhF4EFJPyYZgu8y4NMFq2oImdNQTfNqj+Bv\nZjn2UCPiOyS/jNoEtADviIj/KmRhQ8Xc+gls3NnKhh37i12KmRVZzrvtEbEMWFbAWoakuQ01QHIc\n9dgJo4tcjZkVk28jfZROPGYso8tKfGLKzByoR6ssvROqA9XMHKh5MLehmmUbd7HvoO+EajaSOVDz\nYG7XnVDX7Sx2KWZWRA7UPDi9PrnA/xFfj2o2ojlQ82BCZTkn+E6oZiOeAzVP5tZX88ja7b4TqtkI\n5kDNk7kN1ezY18aqLXuLXYqZFYkDNU/mpHdCXbzGP0M1G6kcqHlyfF0VE3wnVLMRzYGaJ5KYW1/t\nQDUbwRyoeTRveg3PtOxl3bZ9xS7FzIrAgZpHb33FsUhwxyPPFbsUMysCB2oeTZkwmlcdV8sdj64n\nwpdPmY00DtQ8u3TOVNZs3Uezj6WajTgO1Dw7f9bLqCwv4SeL1xe7FDMbYA7UPKuqKOXCU4/hZ49v\nZP/BjmKXY2YDyIFaAJfOmcqeA+0sWPZ8sUsxswFU0ECVdL6kFZJWSrqulzaXSVomaamk27Lm10ta\nIGl5uryxkLXm05nTa5gyYTQ/9m6/2YhSsECVVALcBFwAnAxcIenkbm1mAB8DzoqIU4BrshZ/B/iX\niDgJmAdsLlSt+ZbJiEvnTOGBlVt4fmdrscsxswFSyB7qPGBlRKyKiIPA7cBF3dq8H7gpIrYDRMRm\ngDR4SyPiV+n8PRExpK6Wf8ecqXQG3PGoe6lmI0UhA3UKsC7r+fp0XraZwExJD0haKOn8rPk7JN0h\n6VFJ/5L2eA8h6SpJzZKaW1paCrIRR6pxYhVnNFbzk8W+JtVspChkoKqHed2TpRSYAZwLXAF8XdKE\ndP45wN8DZwDHAVe+ZGURN0dEU0Q01dXV5a/yPLl0zlSeadnLkvW+NYrZSFDIQF0PTMt6PhXY0EOb\nuyKiLSKeBVaQBOx64NH0cEE7cCcwp4C1FsSFpx1DRWnG16SajRCFDNRFwAxJ0yWVA5cD87u1uRM4\nD0DSRJJd/VXpa6sldXU7XwcsK2CtBTFuVBlvPuVlzF+ygQPtvibVbLgrWKCmPcurgXuB5cAPI2Kp\npBskvT1tdi+wVdIy4D7gIxGxNSI6SHb3fy3pCZLDB7cUqtZCunTuVHbub+PXy4fMRQpmdoQ0XE6Y\nNDU1RXNzc7HLeImOzuDVn/01s44dzzeuPKPY5ZhZP0laHBFNubT1L6UKrCQjLjl9Kvc/3ULL7gPF\nLsfMCsiBOgDeOXcKHZ3BXY95nFSz4cyBOgBOmDSWV0wd75+img1zDtQBcuncqTz1/G6WbvA1qWbD\nlQN1gLzttGMpL8nwk8Xe7TcbrhyoA6S6qpzXnzSJux57jraOzmKXY2YF4EAdQJfOmcrWvQe5f8Xg\nGnfAzPLDgTqAXvvyOmqryv1TVLNhyoE6gMpKMlw0ewq/fmoT2/ceLHY5ZpZnDtQB9s65U2nrCO5+\nvPs4MWY21DlQB9jJx47jpGPG+ZpUs2HIgVoEl86ZwuPrd/LHTbuLXYqZ5ZEDtQgumj2Fkoz43kNr\ni12KmeWRA7UI6sZWcFnTVP5r4RpWPO9eqtlw4UAtko+8+UTGjirl43c+6XtOmQ0TDtQiqakq56Pn\nn8jDq7dxxyP+OarZcOBALaJ3NU1j9rQJfOYXy9m5v63Y5ZjZUXKgFlEmIz518Sy27T3IFxesKHY5\nZnaUHKhFNmvKeN7zyga+u3ANTz7nof3MhjIH6iDw4Te9nJqqcv7xzifp7PQJKrOhyoE6CIwfXcY/\nXHgSj63bwQ+a1xW7HDM7Qg7UQeKS06cwb3oNn/vlU2zzwClmQ5IDdZCQxI0XzWJ3azuf/+VTxS7H\nzI6AA3UQefnLxvK+sxq5fdE6Hlm7vdjlmFk/OVAHmb97w0wmj6vg43c+SYdPUJkNKQ7UQWZMRSkf\nf+vJLN2wi+8uXFPscsysHxyog9BbTj2Gs0+YyBcWrKBl94Fil2NmOXKgDkKS+KeLTqG1rYPP3LO8\n2OWYWY4cqIPU8XVjuOo1x3HHo8/x0KqtxS7HzHLgQB3Erj5vBlMmjObjdz1Ja1tHscsxsz44UAex\n0eUl3HjxKTy9aQ9/871HONDuUDUbzByog9zrTpzMpy+ZxW+e2szVtz3KwfbOYpdkZr0oaKBKOl/S\nCkkrJV3XS5vLJC2TtFTSbVnzOyQ9lj7mF7LOwe7dZzZww0Wn8Ktlm/jg9x+lrcOhajYYlRZqxZJK\ngJuANwLrgUWS5kfEsqw2M4CPAWdFxHZJk7JWsT8iZheqvqHmz1/VSFtHcOPPlnHNDx7j3941m9IS\n72CYDSYFC1RgHrAyIlYBSLoduAhYltXm/cBNEbEdICI2F7CeIe8vz55OR2cn/3zPU5RmxJcum01J\nRsUuy8xSheziTAGyx6Jbn87LNhOYKekBSQslnZ+1bJSk5nT+xT29gaSr0jbNLS0t+a1+kLrqNcfz\nkTe/nLse28D/+fHjHj/VbBApZA+1p65T9//7S4EZwLnAVOD3kmZFxA6gPiI2SDoO+I2kJyLimUNW\nFnEzcDNAU1PTiEmWvz3vBNo7gi//99OUZsRn3nEqGfdUzYqukIG6HpiW9XwqsKGHNgsjog14VtIK\nkoBdFBEbACJilaT7gdOBZzAA/u4NM2jv7OSrv1lJaUlybyrJoWpWTIXc5V8EzJA0XVI5cDnQ/Wz9\nncB5AJImkhwCWCWpWlJF1vyzOPTYqwHXvnEmH3jt8XzvobVcP38pESOmk242KBWshxoR7ZKuBu4F\nSoBbI2KppBuA5oiYny57k6RlQAfwkYjYKunVwNckdZKE/mezrw6whCQ+ev7Lae/o5Ov/8ywlmQwf\nf+tJ7qmaFYmGS6+mqakpmpubi11GUUQE/3T3Mr714GqumFfPP77lJKoqCnk0x2zkkLQ4Ippyaev/\n64YBSXzybSdTUZrha79bxe+ebuHGi0/hdSdOLnZpZiOKrwwfJiTxsQtP4scfeBWjy0t437ea+dvb\nHmHz7tZil2Y2YjhQh5mmxhp+/sGzufaNM/nV0k284Yu/5faH1/p6VbMB4EAdhipKS/jg62fwi2vO\n4cRjxnHdHU9w+S0LWbl5T7FLMxvWHKjD2PF1Y7j9/a/kc5eeylMbd3Hhv/2er/z6jx6xyqxAHKjD\nXCYj3nVGPb/+8Lm8edbL+NKvnuYtX/k9zau3Fbs0s2HHgTpC1I2t4KtXnM43rzyDfQc7eOd//oEr\nbl7IXY8954GrzfLE16GOQHsPtPOtB1fz/YfXsn77fqory3jHnKlcMW8aJ0waW+zyzAaV/lyH6kAd\nwTo7gwee2cLtD69jwbLnaesImhqquXxePW859RhGl5cUu0SzonOgWr9t2XOAOx5Zz+0Pr2PVlr2M\nHVXKxbOncPm8aZxy7Phil2dWNA5UO2IRwcPPbuP2Rev4+RMbOdjeycsnj+VVx9dy5vQa5k2voXZM\nRbHLNBswDlTLix37DvLTR5/j18s3s3jNdvant7KeOXkMZ06v5ZXH1TJveg11Yx2wNnw5UC3vDrZ3\n8sRzO1i4ahsPPbuN5tXb2HcwCdjj66o487ikB3vKseOor6mivNQXkNjw4EC1gmvr6OTJ53by0LPb\neGjVVhat3s6eA+0AlGREQ00lx9VVcXzdmBf+Hl83huqq8iJXbtY/DlQbcO0dnTz1/G7+uHk3z2ze\ny6ote3hm816e3bKXg1m3va6uLOP4ujE01FYxeVwFk8ZWMGncqOTv2FFMGlfBqDJfXWCDh4fvswFX\nWpJh1pTxzJpy6BUBHZ3Bc9v380zLnvSxl2da9vDAyi1s2XOA9h4GbRk3qjQrZCuYUFnOuNFljBtV\nyrhRZYwb3fW3jLHpvLGjSn1bbSs6B6oVVElG1NdWUl9byXknTjpkWWdnsG3fQTbvOsDm3a1s3n2A\nlt0H2Lwrmd60q5XmNdvZub+N3a3tfb7X6LISKstLGFVWwujyEkaXJY9R5SWMLsskz9PlFaUllJeI\nspIM5aUZykoylJVmqCjJUFaazk/nlWZESUaUZjLp3/R5Sdd00iaTESUSGSU/+c0ofZ4hmc4IibRN\nMu27KwwvDlQrmkxGTBxTwcQxFZzMuMO27egM9hxoZ1carrta29i1v41drS/O293axv62Dva3ddDa\n1sH+g8n0zv1tbNrZQWt7Ou9gBwc6OgfNIDFSErgZgdALz6Xk1sGSklsIp88zGR0yX+nCrmxW1nrT\nJT0sOzTIX1ie9Zrs5y+0O+Q16nVZ3xud12ZJ2xz/cfrTefW87+zp/Vhz7hyoNiSUZMT40WWMH12W\nt3VGBO2dQVsargc7OmnrCA62dx4yr7Mzadfxwt9O2juyn784vzOS8O+MoLMz6IjkfZJ50JlORzod\naR1dzzsDgvR5Z9fyF+d11Z3drqtNujRtwwt/o/s86Pb80AUvLj/0cEz2s+6nXvpzJibX8zb9OrvT\nj8a1Ywp3YtSBaiOWJMrS3f5KX3xgeeCj+GZmeeJANTPLEweqmVmeOFDNzPLEgWpmlicOVDOzPHGg\nmpnliQPVzCxPhs1oU5JagDX9fNlEYEsByikmb9PQMNy2abhtD7y4TQ0RUZfLC4ZNoB4JSc25Dss1\nVHibhobhtk3DbXvgyLbJu/xmZnniQDUzy5ORHqg3F7uAAvA2DQ3DbZuG2/bAEWzTiD6GamaWTyO9\nh2pmljcOVDOzPBmxgSrpfEkrJK2UdF2x68kHSaslPSHpMUlD8hawkm6VtFnSk1nzaiT9StIf07/V\nxayxP3rZnuslPZd+T49JurCYNfaXpGmS7pO0XNJSSX+Xzh/K31Nv29Sv72pEHkOVVAI8DbwRWA8s\nAq6IiGVFLewoSVoNNEXEkL3AWtJrgD3AdyJiVjrv88C2iPhs+o9fdUR8tJh15qqX7bke2BMRXyhm\nbUdK0jHAMRHxiKSxwGLgYuBKhu731Ns2XUY/vquR2kOdB6yMiFURcRC4HbioyDUZEBG/A7Z1m30R\n8O10+tsk/6EPCb1sz5AWERsj4pF0ejewHJjC0P6eetumfhmpgToFWJf1fD1H8OENQgEskLRY0lXF\nLiaPJkfERkj+wwcm9dF+KLiGgLTDAAAFOklEQVRa0uPpIYEhs2vcnaRG4HTgIYbJ99Rtm6Af39VI\nDdSe7jc7HI59nBURc4ALgL9Ndzdt8PkP4HhgNrAR+GJxyzkyksYAPwGuiYhdxa4nH3rYpn59VyM1\nUNcD07KeTwU2FKmWvImIDenfzcBPSQ5tDAeb0mNcXce6Nhe5nqMSEZsioiMiOoFbGILfk6QykuD5\nXkTckc4e0t9TT9vU3+9qpAbqImCGpOmSyoHLgflFrumoSKpKD6YjqQp4E/Dk4V81ZMwH3ptOvxe4\nq4i1HLWu0EldwhD7niQJ+AawPCK+lLVoyH5PvW1Tf7+rEXmWHyC9/OFfgRLg1oj4dJFLOiqSjiPp\nlQKUArcNxW2S9H3gXJKh0zYBnwTuBH4I1ANrgT+JiCFxoqeX7TmXZBcygNXAX3UdexwKJJ0N/B54\nAuhMZ/8DyTHHofo99bZNV9CP72rEBqqZWb6N1F1+M7O8c6CameWJA9XMLE8cqGZmeeJANTPLEweq\nDQqS7pdU8Ju8SfpgOqLQ97rNb5L0lXT6XEmvzuN7Nkr6057ey4aX0mIXYHa0JJVGRHuOzf8GuCAi\nns2eGRHNQNeQh+eSjBD1YJ5qaAT+FLith/eyYcQ9VMtZ2tNaLumWdMzIBZJGp8te6GFKmpgOJYik\nKyXdKeluSc9KulrStZIelbRQUk3WW7xH0oOSnpQ0L319VTooxaL0NRdlrfdHku4GFvRQ67Xpep6U\ndE067z+B44D5kj7Urf25kn6WDozxAeBD6fiX50iqk/STtIZFks5KX3O9pJslLQC+k34+v5f0SPro\n6uV+FjgnXd+Hut4rXUdN+vk8nn4ep2Wt+9b0c10l6YNZn8fPJS1Jt+1dR/etWl5FhB9+5PQg6Wm1\nA7PT5z8E3pNO308yFiskvwpanU5fCawExgJ1wE7gA+myL5MMQtH1+lvS6dcAT6bT/5z1HhNIxrGt\nSte7Hqjpoc65JL94qQLGAEuB09Nlq4GJPbzmXOBn6fT1wN9nLbsNODudrif5eWJXu8XA6PR5JTAq\nnZ4BNHdfdw/v9VXgk+n064DHstb9IFCRfp5bgTLg0q7PKW03vtj/Xfjx4sO7/NZfz0bEY+n0YpKQ\n7ct9kYwxuVvSTuDudP4TwGlZ7b4PyRiiksZJmkAyJsHbJf192mYUSagB/Cp6/mnj2cBPI2IvgKQ7\ngHOAR3PZwB68ATg5+bk3AOO6xk0A5kfE/nS6DPh3SbOBDmBmDus+myQkiYjfSKqVND5d9vOIOAAc\nkLQZmEzymX1B0udIQvn3R7hNVgAOVOuvA1nTHcDodLqdFw8hjTrMazqznndy6H+D3X8HHSRDLV4a\nESuyF0g6E9jbS409Dc94NDLAq7KCs6sGutXwIZLf678ifU1rDus+3FCS3T/r0oh4WtJc4ELgM5IW\nRMQNOW2FFZyPoVq+rCbZ1QZ45xGu413wwkAVOyNiJ3Av8L/T0YCQdHoO6/kdcLGkynTkrUtIBr7I\n1W6SQxRdFgBXdz1Je6A9GQ9sjGSotz8jGXinp/V1r/Xd6XrPBbbEYcYWlXQssC8ivgt8AZjT18bY\nwHGgWr58AfhrSQ+SHPM7EtvT1/8n8JfpvBtJdqUfV3Kjuxv7Wkkkt7L4FvAwyQhIX4+I/uzu3w1c\n0nVSCvgg0JSeOFpGctKqJ/8PeK+khSS7+12918eB9vRE0oe6veb6rnWTnLx6L4d3KvCwpMeA/wt8\nqh/bZQXm0abMzPLEPVQzszxxoJqZ5YkD1cwsTxyoZmZ54kA1M8sTB6qZWZ44UM3M8uT/A59dGlm5\nH7PgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111dfb5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.655502392344\n",
      "Accuracy: 0.34\n"
     ]
    }
   ],
   "source": [
    "#Load training data\n",
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n",
    "\n",
    "#Flatten and Normalize\n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "#Perform the training\n",
    "# layer_dims = [12288, 20, 7, 5, 1]\n",
    "layer_dims = [12288, 7, 1]\n",
    "parameters = model(train_x, train_y, layer_dims, 2500, 0.01, True)\n",
    "\n",
    "#Test the model\n",
    "pred_train = predict(train_x, train_y, parameters)\n",
    "pred_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(dims):\n",
    "    parameters = {}\n",
    "    L = len(dims)\n",
    "    for l in range(1, L):\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(dims[l], dims[l-1]) * 0.01\n",
    "        parameters[\"b\" + str(l)] = np.zeros((dims[l], 1), dtype=float)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forwardPropagation(X, parameters):\n",
    "    L = len(parameters)//2\n",
    "    A = X\n",
    "    caches = []\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        W = parameters[\"W\" + str(l)]\n",
    "        b = parameters[\"b\" + str(l)]\n",
    "        A,cache = linear_activation_forward(A_prev, W, b, \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    #For final layer\n",
    "    W = parameters[\"W\" + str(L)]\n",
    "    b = parameters[\"b\" + str(L)]\n",
    "    AL,cache = linear_activation_forward(A, W, b, \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return AL, caches\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "    if activation==\"relu\":\n",
    "        A, activation_cache = relu(Z)\n",
    "    else:\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache\n",
    "    \n",
    "def linear_forward(A_prev, W, b):\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    cache = (A_prev, W, b)\n",
    "    return Z, cache\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0, Z)\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = (-1/m) * ((np.dot(Y, np.log(AL.T))) + (np.dot(1-Y, np.log(1-AL.T))))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagation(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    \n",
    "    #for final layer\n",
    "    grads[\"dA\" + str(L)] = -(np.divide(Y, AL)) + np.divide(1-Y, 1-AL)\n",
    "    current_cache = caches[L - 1]\n",
    "    grads[\"dA\" + str(L - 1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backwards(grads[\"dA\" + str(L)], current_cache, \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L - 1)):\n",
    "        current_cache = caches[l]\n",
    "        grads[\"dA\" + str(l)], grads[\"dW\" + str(l+1)], grads[\"db\" + str(l+1)] = linear_activation_backwards(grads[\"dA\" + str(l + 1)], current_cache, \"relu\")\n",
    "        \n",
    "    return grads\n",
    "\n",
    "def linear_activation_backwards(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backwards(dA, activation_cache)\n",
    "    else:\n",
    "        dZ = sigmoid_backwards(dA, activation_cache)\n",
    "    \n",
    "    dA_prev, dW, db = linear_backwards(dZ, linear_cache)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "    \n",
    "def linear_backwards(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = (1/m) * np.dot(dZ, A_prev.T)\n",
    "    db = (1/m) * np.sum(dZ, axis = 1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    return dA_prev, dW, db\n",
    "    \n",
    "\n",
    "def relu_backwards(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z<=0] = 0\n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backwards(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1 / (1 + np.exp(-Z))\n",
    "    dZ = dA * s * (1 - s)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateParameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters)//2\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] -= learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] -= learning_rate * grads[\"db\" + str(l+1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
